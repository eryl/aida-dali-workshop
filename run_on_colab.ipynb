{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UD-kpPhceZRA"
      },
      "source": [
        "# ! Remember to set the runtime type to GPU !"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuuX9GrhY64D"
      },
      "source": [
        "# NVIDIA DALI on Colab\n",
        "\n",
        "We will use this notebook to execute shell commands.\n",
        "The first thing we do is clone the repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIEVkhODY_-L"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/eryl/aida-dali-workshop.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git -C /content/aida-dali-workshop/ pull   # update the codebase"
      ],
      "metadata": {
        "id": "ThNoZJ2mYYXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ScF6hECcd_jQ"
      },
      "outputs": [],
      "source": [
        "!pip install monai nibabel > /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now check which version of cuda is installed by running the command below"
      ],
      "metadata": {
        "id": "3v-Nmf5PToek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "id": "2qSNSDwcTk0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we run this, it says CUDA 12.2, so that's the DALI version we'll install"
      ],
      "metadata": {
        "id": "bPl93R1dTtcj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nvidia-dali-cuda120"
      ],
      "metadata": {
        "id": "u9jgEXxrTzWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running scripts\n",
        "The code we clone is in /content/aida-dali-workshop. We'll start by making that our working directory"
      ],
      "metadata": {
        "id": "sQmo8z3ZUAIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/aida-dali-workshop/"
      ],
      "metadata": {
        "id": "E1qWprp7T_Sv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "RfubncuMULKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The first training script\n",
        "We can now run the first training script. It will download the image dataset we'll use (the Oxford IIIT pets dataset)."
      ],
      "metadata": {
        "id": "EwGEK7MgUQbG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python examples/train_pet_resnet.py"
      ],
      "metadata": {
        "id": "Tv3Oub7PUMFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What we're mostly interested in this case is how long the training epoch takes compared to our other data loading methods."
      ],
      "metadata": {
        "id": "HzzcbeRxVhPf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The DALI version\n",
        "Now try to run the DALI version and compare the training time"
      ],
      "metadata": {
        "id": "YrTJtRNwV0OE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python examples/train_pet_resnet_dali.py"
      ],
      "metadata": {
        "id": "PkDcepDFV0OK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Did you notice any difference in time it took to process the batches (how many iterations per second did the two methods achieve)?"
      ],
      "metadata": {
        "id": "aNPCJeJJWolh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-augmenting the data\n",
        "We've looked at how we can offload the augmentation to the GPU using DALI. As we get more powerful GPUs this will probably become more important to gain speedups in utilization.\n",
        "\n",
        "Another way to speed up dataloading is to perform the augmentation ahead of time. This only makes sense if you have plenty storage and will be using the training dataset to train multiple models, but if you plan to run large amounts of cross validation you will likely see significant speedups.\n",
        "\n",
        "One downside to this method is that we need to generate different augmentations for each epoch (the core idea of data augmentations is that the exact same image should never occur multiple times in the training data). This means that storage requierments will increase with the planned number of epochs."
      ],
      "metadata": {
        "id": "6sVZB9x2W1fV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python examples/train_pet_resnet_preaugmented.py"
      ],
      "metadata": {
        "id": "F-fUgdSFWyj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! du -sh data"
      ],
      "metadata": {
        "id": "QJaAG4CQUWCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5Zxncb4MY1co"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}